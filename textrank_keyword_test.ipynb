{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# tokenizer import\n",
    "from konlpy.tag import Okt, Komoran, Hannanum, Kkma\n",
    "\n",
    "#운영체제에 따라 mecab설치 방법이 다름.\n",
    "if platform.system() == \"Windows\":\n",
    "    try:\n",
    "        from eunjeon import Mecab\n",
    "    except:\n",
    "        print(\"please install eunjeon module\")\n",
    "else:  # Ubuntu일 경우\n",
    "    from konlpy.tag import Mecab\n",
    "\n",
    "from typing import List, Callable, Union, Any, TypeVar, Tuple, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./sents.txt\", \"r\") as f:\n",
    "    sents = f.read().split(\"\\n\")\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(tokenizer_name):\n",
    "    if tokenizer_name == \"komoran\":\n",
    "        tokenizer = Komoran()\n",
    "    elif tokenizer_name == \"okt\":\n",
    "        tokenizer = Okt()\n",
    "    elif tokenizer_name == \"mecab\":\n",
    "        tokenizer = Mecab()\n",
    "    elif tokenizer_name == \"hannanum\":\n",
    "        tokenizer = Hannanum()\n",
    "    elif tokenizer_name == \"kkma\":\n",
    "        tokenizer = Kkma()\n",
    "    else:\n",
    "        tokenizer = Mecab()\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(sent: List[str], noun=True, tokenizer=\"mecab\") -> List[str]:\n",
    "    tokenizer = get_tokenizer(tokenizer)\n",
    "\n",
    "    if noun:\n",
    "        nouns = tokenizer.nouns(sent)\n",
    "        print('n',nouns)\n",
    "        nouns = [word for word in nouns if len(word) > 1]\n",
    "        print('nouns',nouns)\n",
    "        return nouns\n",
    "    \n",
    "    return tokenizer.morphs(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\"연합뉴스\", \"가방\"]\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    stop_words=stopwords,\n",
    "    tokenizer=partial(get_tokens, noun=True, tokenizer=\"mecab\"),\n",
    "    min_df=2,\n",
    ")\n",
    "\n",
    "\n",
    "# 코퍼스로부터 각 단어의 빈도 수를 기록.\n",
    "x = vectorizer.fit_transform(sents)\n",
    "x.toarray().shape\n",
    "print(x.toarray())\n",
    "\n",
    "\n",
    "# 각 단어의 인덱스가 어떻게 부여되었는지를 보여줌.\n",
    "vocab_idx = vectorizer.vocabulary_\n",
    "print(vocab_idx)\n",
    "idx_vocab = {idx: vocab for vocab, idx in vocab_idx.items()}\n",
    "print(idx_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-consensus",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sents(\n",
    "    sents: List[str], stopwords=None, min_count=2, tokenizer=\"mecab\", noun=True\n",
    "):\n",
    "\n",
    "    vectorizer = CountVectorizer(\n",
    "        stop_words=stopwords,\n",
    "        tokenizer=partial(get_tokens, noun=noun, tokenizer=\"mecab\"),\n",
    "        min_df=min_count,\n",
    "    )\n",
    "\n",
    "    vec = vectorizer.fit_transform(sents)\n",
    "    print(vec)\n",
    "    vocab_idx = vectorizer.vocabulary_\n",
    "    print(vocab_idx)\n",
    "    idx_vocab = {idx: vocab for vocab, idx in vocab_idx.items()}\n",
    "    print(idx_vocab)\n",
    "    \n",
    "    return vec, vocab_idx, idx_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary csr_matrix\n",
    "numerators = (x > 0) * 1\n",
    "\n",
    "# Inverse sentence length\n",
    "min_length = 1\n",
    "denominators = np.asarray(x.sum(axis=1))\n",
    "denominators[np.where(denominators <= min_length)] = 10000\n",
    "denominators = np.log(denominators)\n",
    "\n",
    "denom_log1 = np.matmul(denominators, np.ones(denominators.shape).T)\n",
    "denom_log2 = np.matmul(np.ones(denominators.shape), denominators.T)\n",
    "\n",
    "sim_mat = np.dot(numerators, numerators.T)\n",
    "\n",
    "sim_mat = sim_mat / (denom_log1 + denom_log2)\n",
    "\n",
    "min_sim = 0.3\n",
    "sim_mat[np.where(sim_mat <= min_sim)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-dylan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-garden",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-costs",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-surrey",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-plasma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-amateur",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
