{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "narrative-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "import math\n",
    "import kss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-ghost",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-sector",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-queensland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "sorted-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = \"\"\" 인도에 이어 베트남에서 신종 코로나 바이러스 감염증(코로나19) 변이 바이러스가 확산함에 따라 현지에서 대규모 생산시설을 운영하고 있는 삼성전자와 LG전자에도 비상이 걸렸다. 베트남 지방정부가 코로나19 확산 방지를 위해 이동제한 등의 방역조치를 시행하고 있어 각 시설 생산 차질 우려가 나오는 것이다.3일(현지시각) 베트남 보건당국에 따르면 북부 박장성(北江省)과 박닌성(北寧省) 지역에서는 전날 각각 48명, 3명의 신규 확진자가 발생했다. 지난 4월 27일 이후 전날까지 이 지역 누적 확진자는 박장성 2424명, 박닌성 879명으로, 같은 기간 베트남 전체 확진자(4549명)의 72.6%를 차지하고 있다.이곳에는 삼성전자를 비롯한 전자 계열사들이 대규모 생산시설을 운영 중에 있다. 박닌성 옌퐁에는 약 2만명이 일하고 있는 삼성전자의 스마트폰 공장이 있는데, 이 공장은 삼성전자의 전 세계 스마트폰 출하량의 절반 이상을 담당하고 있는 것으로 알려졌다. 또 삼성디스플레이(직원수 약 3만5000명)와 삼성SDI(2400명)도 해당 지역에서 각각 디스플레이 패널, 배터리 공장을 운영하고 있다.삼성전자는 지난달 박장성 협력업체 직원 40여명이 코로나19에 집단 감염돼 공장 가동이 멈추는 바람에 부품 공급에 애를 먹었다. 이 상황에서 스마트폰 공장의 현지 근로자 2명이 지난달 12일 확진 판정을 받기도 했다. 다만 이들은 유행이 본격화한 4월 말부터 휴가 중으로, 공장 출근을 하지 않아 다른 직원과의 접촉은 없었던 것으로 전해졌다. 공장 가동 중단도 이뤄지지 않았다.여기에 베트남 각 지역 정부들이 1일 오전 0시(현지시각)을 기해 해당 지역에 이동제한 명령을 내리면서 생산 차질이 일부 우려되는 상황이다. 72시간 이내의 코로나19 진단검사에서 음성이 확인될 경우에는 출퇴근이 가능하다고 하지만, 업무에는 상당한 영향이 아닐 수 없다. 현재 삼성전자 스마트폰 공장 직원 2만명 중 절반쯤이 외부 지역에서 출퇴근을 하고 있는 것으로 알려졌다. 삼성전자 관계자는 “현재 공장 내 기숙사에 들어가면 2주간 외부 출입을 하지 못하도록 조치하고 있다”라며 “최대한 (직원들이) 이동하지 않게끔 인근 숙박시설을 마련하는 등 대책을 마련하고 있다”고 했다.공장 내 집단감염이 현실화 할 경우 생산차질로 인한 피해는 막심할 수밖에 없다. 특히 보통 글로벌 기업의 대규모 공장 인근에는 이들의 부품을 조달하는 협력사들도 많아 코로나19 확산은 자칫 공급망 전체의 위기로 번질 가능성이 있다. 국내 중소기업의 베트남 현지 공장 150여곳이 최근 코로나19 확산 여파로 가동을 멈추기도 했다.이 때문에 삼성전자는 현지 직원을 대상으로 한 백신 접종에도 돌입했다. 전자 계열사인 삼성디스플레이와 삼성SDI 등의 직원들도 함께 백신을 맞는다. 해당 백신은 베트남 정부가 기업별로 할당한 영국 아스트라제네카 백신으로, 삼성 계열 3사의 접종 대상자는 1만5000여명이라는 게 회사 측 설명이다. 이들의 협력사에도 백신이 지원될 것으로 알려졌다. 회사 관계자는 “우선 생산라인의 현지인 직원들을 대상으로 백신 접종을 시작했다”라며 “한국인 주재원들의 접종 신청도 받고 있다”고 했다.문제는 최근 베트남에서 영국 변이 바이러스와 인도 변이 바이러스의 특성이 섞인 신종 변이 바이러스가 발견됐다는 점이다. 영국 변이는 전염성이 높아 확산이 빠르고, 인도 변이는 코로나19를 무력화하는 중화항체가 잘 듣지 않는다. 응우옌 탄 롱 베트남 보건부 장관은 “새 변이 바이러스는 공기를 통해 빠르게 전파되며, 배양 실험에서 이전 바이러스보다 더 빠르게 자기 복제가 이뤄지는 모습이 관찰됐다”고 밝혔다.코로나19가 확산하는 지역은 아니지만 역시 베트남에 생산거점을 두고 있는 LG전자도 현지 상황을 면밀하게 관찰하고 있다. LG전자는 베트남 북부 하이퐁시에 지난 2015년 ‘LG 하이퐁 캠퍼스’를 설립하고, 다양한 생활가전 제품을 생산하고 있다. 현지 직원은 약 1만6000명이다. 자동차 부품을 만드는 공장도 있다. 또 LG디스플레이, LG이노텍 등의 계열사 공장이 있다.LG전자 관계자는 “공장의 일부 생산라인의 가동률을 조정하고, 박장성이나 박닌성으로부터 출퇴근하는 근로자의 임시 거처 숙소비를 지원하는 등의 대응을 짜고 있다”라며 “최악의 상황에 대비한 대응 전략을 갖추고 있다”고 했다. LG디스플레이와 LG이노텍 역시 비슷한 대책을 세우고 있다. LG디스플레이와 이노텍 측은 “현지는 아직 코로나19의 급격한 확산이 일어나지는 않고 있으나, 상황을 예의주시하고 있다”고 했다. 코로나19 급속 확산 베트남…삼성·LG, 공급망 무너질까 노심초사.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "religious-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "news1 = \"\"\" 국내 신종 코로나바이러스 감염증(코로나19) 신규 확진자가 하루만에 600명대로 올라섰다.전국적으로 크고 작은 일상 감염이 잇따르는 상황에서 해외유입 변이 바이러스도 빠르게 확산되고 있어 당국이 촉각을 세우고 있다. 정부는 오는 21일 다음주부터 적용할 사회적 거리두기 조정안을 발표할 예정이다.19일 중앙방역대책본부(중대본)에 따르면 이날 0시 기준 코로나19 신규 확진자는 654명으로 전날(528명)보다 126명 늘었다.누적 확진자는 13만3471명이다.확진자 수는 보통 주말·휴일 검사건수 감소 영향으로 인해 주 초반에는 비교적 적게 나오다가 중반부터 증가하는 경향을 보인다.이날 신규 확진자의 감염경로는 지역발생이 637명, 해외유입이 17명이다.지역별로는 서울 245명, 경기 159명, 인천 23명 등 수도권이 427명(67%)이다.주요 집단발병 사례를 보면 노래연습장, 유흥업소 등 다중이용시설을 고리로 새로운 감염이 확인됐다.수도권에서는 서울 강동구 노래연습장과 관련해 41명, 서울 노원구 고시원에서 11명, 경기 성남시 일가족-지인 사례에서 19명이 각각 양성 판정을 받았다.앞서 발생한 인천국제공항 검역소 집단감염과 관련해선 8명이 인도 변이에 감염된 것으로 확인됐다. 역학적 관련성이 있는 나머지 7명까지 포함하면 15명 전원이 인도 변이 감염자인 셈이다.최근 코로나19 발생 양상을 보면 전국에서 집단감염이 잇따르면서 '4차 유행'이 지속하고 있다.지난 13일부터 이날까지 최근 1주일간 하루 평균 신규 확진자는 약 651명꼴이다. 이중 '사회적 거리두기' 단계 조정의 핵심 지표인 일평균 지역발생 확진자는 약 628명으로, 여전히 2.5단계(전국 400∼500명 이상 등) 범위다.사망자는 전날보다 8명 늘어 누적 1912명이 됐다. 국내 평균 치명률은 1.43%다.전날 하루 선별진료소를 통한 검사 건수는 3만3640건으로, 직전일(4만1704건)보다 19% 적다.검사건수 대비 확진자를 계산한 양성률은 1.94%(3만3640명 중 654명)로, 직전일 1.27%(4만1704명 중 528명)보다 상승했다.정부는 오는 21일 다음주부터 3주간 적용할 사회적 거리두기 조정안을 발표한다. 현재 수도권에서는 2단계, 비수도권에서는 1.5단계의 거리두기 조처가 이뤄지고 있다.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "rough-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "news2 = \"\"\"경북 영천에서 17일 하루 만에 신종 코로나바이러스 감염증(코로나19) 확진자가 5명이 발생, N차 감염이 우려되는 가운데 비상이 걸렸다. 지난 7일 80번 확진자 이후 열흘 만에 지역 누적 확진자는 85명으로 늘어났다.영천시에 따르면 경산에 주소를 둔 공부방 교사가 확진됐다는 소식을 접한 A여고 한 학생이 지난 16일 보건소 검체 검사 결과 17일 양성판정을 받았다.또 확진자 교사가 운영 중인 공부방에서 과외 학습을 받고 있는 B여고 학생이 17일 오후 8시 확진 판정을 받은 가운데 A여고 학생 부모와 B여고 학생 엄마 등 총 5명이 코로나 판정을 받았다.수업을 받은 나머지 학생들은 모두 음성 판정을 받은 것으로 알려졌다.이날 A여고 측은 학생, 교직원 등 140여 명이 보건소에서 검체를 실시했으며 뒤늦게 알려진 B여고는 18일 학생과 교직원들이 검사를 받을 예정이다.이에 보건소는 코로나 확진자들을 자가 격리하고 이들의 이동 동선 파악에 집중하는 가운데 학교 등의 방역소독을 철저히 하고 있다.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "photographic-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "news3 =\"\"\" 브라질, 인도발 코로나 변이 상륙할라…긴장 속 모니터링 강화 (상파울루=연합뉴스) 김재순 특파원 = 브라질 보건당국이 인도발 신종 코로나바이러스 감염증(코로나19) 변이 바이러스 상륙 가능성에 긴장하고 있다.18일(현지시간) 브라질 언론에 따르면 상파울루시 당국은 인도발 변이 바이러스가 브라질에서도 나타날 가능성이 크다는 지적에 따라 상파울루주 정부 산하 부탄탕연구소와 함께 모니터링을 강화하기로 했다고 밝혔다.상파울루시는 브라질에서 코로나19 확진자와 사망자가 가장 먼저 나온 곳으로, 인근 과룰류스 국제공항을 통해 외국인 입국이 대규모로 이뤄지고 있다.상파울루시 관계자는 이날 기자회견을 통해 \"인도발 변이 바이러스 상륙을 막기 위한 사전 조치로 부탄탕연구소와 협력해 외국인에 대한 철저한 추적 관찰이 이뤄질 것\"이라고 말했다.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "western-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "news4 = \"\"\" 코로나 방역 모범국으로 평가받던 대만, 베트남, 싱가포르에서 최근 코로나 확진자가 크게 늘면서 방역에 비상이 걸렸다. 결국 백신 접종이 이뤄지지 않으면 코로나 확산세를 억제하기는 어렵다는 지적이 나온다. 미 블룸버그통신은 대만과 싱가포르가 자국내 방역 단계를 빠르게 격상시키고 있다고 16일 보도했다. 대만 정부는 이번 주말에 시민들이 집에서 머무르도록 권고하고, 실내 모임은 최대 5명, 야외 모임은 10명까지 제한했다. 국제 통계사이트 월드오미터 기준 대만에서 16일 보고된 코로나 신규 확진자는 207명으로 최고치를 기록했다.싱가포르 역시 식당 내에서의 식사를 금지하고 재택근무를 의무화했으며, 사적 모임은 최대 2인까지로 제한했다. 싱가포르 정부가 이런 봉쇄 정책을 실시한 것은 지난해 4~5월 이후 1년 만이다. 16일 보고된 싱가포르 신규 확진자는 49명이지만, 5월 초부터 집단 감염이 발생하자 경계 수위를 높였다. 또 최근 21일간 대만 여행 이력이 있는 외국인의 입국을 금지했다.대만과 싱가포르는 지난 12월 양국 간의 여행 제한 조치를 완화했었다. 양국에서 서로 체류하다 온 이들에 대해 자가격리 절차를 면제해 주기로 한 것이다. 하지만 자국 내 코로나 확산세가 심해지면서 여행객들에 대한 빗장도 다시 걸어 잠갔다.베트남은 이날 월드오미터 기준 127명의 신규 확진자가 보고됐다. 그 전날에는 165명의 확진자가 보고됐는데, 이는 지난해 1월 베트남에서 코로나가 처음 발병한 이래 최고치다. 북부 바짱주의 꽝차우 산업단지에서 집단감염이 일어나면서 확진자 수가 치솟았다.블룸버그는 이런 현상에 대해 “지역 사회에 대한 백신 접종 없이 바이러스로부터 안전한 환경을 만드는 게 얼마나 어려운지를 보여주는 사례”라고 했다. 블룸버그에 따르면 대만의 백신 접종률은 1% 미만이고, 베트남 역시 백신 접종률은 인구의 1% 수준이다. 싱가포르는 발빠르게 백신 확보에 나선 나라 중 하나이지만, 지금까지 한번이라도 백신을 맞은 국민은 전체 인구의 3분의 1 정도다.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-symbol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "demographic-precipitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['인도에 이어 베트남에서 신종 코로나 바이러스 감염증(코로나19) 변이 바이러스가 확산함에 따라 현지에서 대규모 생산시설을 운영하고 있는 삼성전자와 LG전자에도 비상이 걸렸다.', '베트남 지방정부가 코로나19 확산 방지를 위해 이동제한 등의 방역조치를 시행하고 있어 각 시설 생산 차질 우려가 나오는 것이다.', '3일(현지시각) 베트남 보건당국에 따르면 북부 박장성(北江省)과 박닌성(北寧省) 지역에서는 전날 각각 48명, 3명의 신규 확진자가 발생했다.', '지난 4월 27일 이후 전날까지 이 지역 누적 확진자는 박장성 2424명, 박닌성 879명으로, 같은 기간 베트남 전체 확진자(4549명)의 72.6%를 차지하고 있다.', '이곳에는 삼성전자를 비롯한 전자 계열사들이 대규모 생산시설을 운영 중에 있다.', '박닌성 옌퐁에는 약 2만명이 일하고 있는 삼성전자의 스마트폰 공장이 있는데, 이 공장은 삼성전자의 전 세계 스마트폰 출하량의 절반 이상을 담당하고 있는 것으로 알려졌다.', '또 삼성디스플레이(직원수 약 3만5000명)와 삼성SDI(2400명)도 해당 지역에서 각각 디스플레이 패널, 배터리 공장을 운영하고 있다.', '삼성전자는 지난달 박장성 협력업체 직원 40여명이 코로나19에 집단 감염돼 공장 가동이 멈추는 바람에 부품 공급에 애를 먹었다.', '이 상황에서 스마트폰 공장의 현지 근로자 2명이 지난달 12일 확진 판정을 받기도 했다.', '다만 이들은 유행이 본격화한 4월 말부터 휴가 중으로, 공장 출근을 하지 않아 다른 직원과의 접촉은 없었던 것으로 전해졌다.', '공장 가동 중단도 이뤄지지 않았다.', '여기에 베트남 각 지역 정부들이 1일 오전 0시(현지시각)을 기해 해당 지역에 이동제한 명령을 내리면서 생산 차질이 일부 우려되는 상황이다.', '72시간 이내의 코로나19 진단검사에서 음성이 확인될 경우에는 출퇴근이 가능하다고 하지만, 업무에는 상당한 영향이 아닐 수 없다.', '현재 삼성전자 스마트폰 공장 직원 2만명 중 절반쯤이 외부 지역에서 출퇴근을 하고 있는 것으로 알려졌다.', '삼성전자 관계자는 “현재 공장 내 기숙사에 들어가면 2주간 외부 출입을 하지 못하도록 조치하고 있다”라며 “최대한 (직원들이) 이동하지 않게끔 인근 숙박시설을 마련하는 등 대책을 마련하고 있다”고 했다.', '공장 내 집단감염이 현실화 할 경우 생산차질로 인한 피해는 막심할 수밖에 없다.', '특히 보통 글로벌 기업의 대규모 공장 인근에는 이들의 부품을 조달하는 협력사들도 많아 코로나19 확산은 자칫 공급망 전체의 위기로 번질 가능성이 있다.', '국내 중소기업의 베트남 현지 공장 150여곳이 최근 코로나19 확산 여파로 가동을 멈추기도 했다.', '이 때문에 삼성전자는 현지 직원을 대상으로 한 백신 접종에도 돌입했다.', '전자 계열사인 삼성디스플레이와 삼성SDI 등의 직원들도 함께 백신을 맞는다.', '해당 백신은 베트남 정부가 기업별로 할당한 영국 아스트라제네카 백신으로, 삼성 계열 3사의 접종 대상자는 1만5000여명이라는 게 회사 측 설명이다.', '이들의 협력사에도 백신이 지원될 것으로 알려졌다.', '회사 관계자는 “우선 생산라인의 현지인 직원들을 대상으로 백신 접종을 시작했다”라며 “한국인 주재원들의 접종 신청도 받고 있다”고 했다.', '문제는 최근 베트남에서 영국 변이 바이러스와 인도 변이 바이러스의 특성이 섞인 신종 변이 바이러스가 발견됐다는 점이다.', '영국 변이는 전염성이 높아 확산이 빠르고, 인도 변이는 코로나19를 무력화하는 중화항체가 잘 듣지 않는다.', '응우옌 탄 롱 베트남 보건부 장관은 “새 변이 바이러스는 공기를 통해 빠르게 전파되며, 배양 실험에서 이전 바이러스보다 더 빠르게 자기 복제가 이뤄지는 모습이 관찰됐다”고 밝혔다.', '코로나19가 확산하는 지역은 아니지만 역시 베트남에 생산거점을 두고 있는 LG전자도 현지 상황을 면밀하게 관찰하고 있다.', 'LG전자는 베트남 북부 하이퐁시에 지난 2015년 ‘LG 하이퐁 캠퍼스’를 설립하고, 다양한 생활가전 제품을 생산하고 있다.', '현지 직원은 약 1만6000명이다.', '자동차 부품을 만드는 공장도 있다.', '또 LG디스플레이, LG이노텍 등의 계열사 공장이 있다.', 'LG전자 관계자는 “공장의 일부 생산라인의 가동률을 조정하고, 박장성이나 박닌성으로부터 출퇴근하는 근로자의 임시 거처 숙소비를 지원하는 등의 대응을 짜고 있다”라며 “최악의 상황에 대비한 대응 전략을 갖추고 있다”고 했다.', 'LG디스플레이와 LG이노텍 역시 비슷한 대책을 세우고 있다.', 'LG디스플레이와 이노텍 측은 “현지는 아직 코로나19의 급격한 확산이 일어나지는 않고 있으나, 상황을 예의주시하고 있다”고 했다.', '코로나19 급속 확산 베트남…삼성·LG, 공급망 무너질까 노심초사.']\n"
     ]
    }
   ],
   "source": [
    "text_list = kss.split_sentences(sents)\n",
    "print(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-resort",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "exact-division",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def scan_vocabulary(sents, tokenize=None, min_count=2):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    sents : list of str\n",
    "        Sentence list\n",
    "    tokenize : callable\n",
    "        tokenize(str) returns list of str\n",
    "    min_count : int\n",
    "        Minumum term frequency\n",
    "    Returns\n",
    "    -------\n",
    "    idx_to_vocab : list of str\n",
    "        Vocabulary list\n",
    "    vocab_to_idx : dict\n",
    "        Vocabulary to index mapper.\n",
    "    \"\"\"\n",
    "    counter = Counter(w for sent in sents for w in tokenize(sent))\n",
    "    counter = {w:c for w,c in counter.items() if c >= min_count}\n",
    "    idx_to_vocab = [w for w, _ in sorted(counter.items(), key=lambda x:-x[1])]\n",
    "    vocab_to_idx = {vocab:idx for idx, vocab in enumerate(idx_to_vocab)}\n",
    "    return idx_to_vocab, vocab_to_idx\n",
    "\n",
    "def tokenize_sents(sents, tokenize):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    sents : list of str\n",
    "        Sentence list\n",
    "    tokenize : callable\n",
    "        tokenize(sent) returns list of str (word sequence)\n",
    "    Returns\n",
    "    -------\n",
    "    tokenized sentence list : list of list of str\n",
    "    \"\"\"\n",
    "    return [tokenize(sent) for sent in sents]\n",
    "\n",
    "def vectorize(tokens, vocab_to_idx):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    tokens : list of list of str\n",
    "        Tokenzed sentence list\n",
    "    vocab_to_idx : dict\n",
    "        Vocabulary to index mapper\n",
    "    Returns\n",
    "    -------\n",
    "    sentence bow : scipy.sparse.csr_matrix\n",
    "        shape = (n_sents, n_terms)\n",
    "    \"\"\"\n",
    "    rows, cols, data = [], [], []\n",
    "    for i, tokens_i in enumerate(tokens):\n",
    "        for t, c in Counter(tokens_i).items():\n",
    "            j = vocab_to_idx.get(t, -1)\n",
    "            if j == -1:\n",
    "                continue\n",
    "            rows.append(i)\n",
    "            cols.append(j)\n",
    "            data.append(c)\n",
    "    n_sents = len(tokens)\n",
    "    n_terms = len(vocab_to_idx)\n",
    "    x = csr_matrix((data, (rows, cols)), shape=(n_sents, n_terms))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-settle",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "honey-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "\n",
    "def sent_graph(sents, tokenize=None, min_count=2, min_sim=0.3,\n",
    "    similarity=None, vocab_to_idx=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    sents : list of str\n",
    "        Sentence list\n",
    "    tokenize : callable\n",
    "        tokenize(sent) return list of str\n",
    "    min_count : int\n",
    "        Minimum term frequency\n",
    "    min_sim : float\n",
    "        Minimum similarity between sentences\n",
    "    similarity : callable or str\n",
    "        similarity(s1, s2) returns float\n",
    "        s1 and s2 are list of str.\n",
    "        available similarity = [callable, 'cosine', 'textrank']\n",
    "    vocab_to_idx : dict\n",
    "        Vocabulary to index mapper.\n",
    "        If None, this function scan vocabulary first.\n",
    "    verbose : Boolean\n",
    "        If True, verbose mode on\n",
    "    Returns\n",
    "    -------\n",
    "    sentence similarity graph : scipy.sparse.csr_matrix\n",
    "        shape = (n sents, n sents)\n",
    "    \"\"\"\n",
    "\n",
    "    if vocab_to_idx is None:\n",
    "        idx_to_vocab, vocab_to_idx = scan_vocabulary(sents, tokenize, min_count)\n",
    "    else:\n",
    "        idx_to_vocab = [vocab for vocab, _ in sorted(vocab_to_idx.items(), key=lambda x:x[1])]\n",
    "\n",
    "    x = vectorize_sents(sents, tokenize, vocab_to_idx)\n",
    "    if similarity == 'cosine':\n",
    "        x = numpy_cosine_similarity_matrix(x, min_sim, verbose, batch_size=1000)\n",
    "    else:\n",
    "        x = numpy_textrank_similarity_matrix(x, min_sim, verbose, batch_size=1000)\n",
    "    return x\n",
    "\n",
    "def vectorize_sents(sents, tokenize, vocab_to_idx):\n",
    "    rows, cols, data = [], [], []\n",
    "    for i, sent in enumerate(sents):\n",
    "        counter = Counter(tokenize(sent))\n",
    "        for token, count in counter.items():\n",
    "            j = vocab_to_idx.get(token, -1)\n",
    "            if j == -1:\n",
    "                continue\n",
    "            rows.append(i)\n",
    "            cols.append(j)\n",
    "            data.append(count)\n",
    "    n_rows = len(sents)\n",
    "    n_cols = len(vocab_to_idx)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(n_rows, n_cols))\n",
    "\n",
    "def numpy_cosine_similarity_matrix(x, min_sim=0.3, verbose=True, batch_size=1000):\n",
    "    n_rows = x.shape[0]\n",
    "    mat = []\n",
    "    for bidx in range(math.ceil(n_rows / batch_size)):\n",
    "        b = int(bidx * batch_size)\n",
    "        e = min(n_rows, int((bidx+1) * batch_size))\n",
    "        psim = 1 - pairwise_distances(x[b:e], x, metric='cosine')\n",
    "        rows, cols = np.where(psim >= min_sim)\n",
    "        data = psim[rows, cols]\n",
    "        mat.append(csr_matrix((data, (rows, cols)), shape=(e-b, n_rows)))\n",
    "        if verbose:\n",
    "            print('\\rcalculating cosine sentence similarity {} / {}'.format(b, n_rows), end='')\n",
    "    mat = sp.sparse.vstack(mat)\n",
    "    if verbose:\n",
    "        print('\\rcalculating cosine sentence similarity was done with {} sents'.format(n_rows))\n",
    "    return mat\n",
    "\n",
    "def numpy_textrank_similarity_matrix(x, min_sim=0.3, verbose=True, min_length=1, batch_size=1000):\n",
    "    n_rows, n_cols = x.shape\n",
    "\n",
    "    # Boolean matrix\n",
    "    rows, cols = x.nonzero()\n",
    "    data = np.ones(rows.shape[0])\n",
    "    z = csr_matrix((data, (rows, cols)), shape=(n_rows, n_cols))\n",
    "\n",
    "    # Inverse sentence length\n",
    "    size = np.asarray(x.sum(axis=1)).reshape(-1)\n",
    "    size[np.where(size <= min_length)] = 10000\n",
    "    size = np.log(size)\n",
    "\n",
    "    mat = []\n",
    "    for bidx in range(math.ceil(n_rows / batch_size)):\n",
    "\n",
    "        # slicing\n",
    "        b = int(bidx * batch_size)\n",
    "        e = min(n_rows, int((bidx+1) * batch_size))\n",
    "\n",
    "        # dot product\n",
    "        inner = z[b:e,:] * z.transpose()\n",
    "\n",
    "        # sentence len[i,j] = size[i] + size[j]\n",
    "        norm = size[b:e].reshape(-1,1) + size.reshape(1,-1)\n",
    "        norm = norm ** (-1)\n",
    "        norm[np.where(norm == np.inf)] = 0\n",
    "\n",
    "        # normalize\n",
    "        sim = inner.multiply(norm).tocsr()\n",
    "        rows, cols = (sim >= min_sim).nonzero()\n",
    "        data = np.asarray(sim[rows, cols]).reshape(-1)\n",
    "\n",
    "        # append\n",
    "        mat.append(csr_matrix((data, (rows, cols)), shape=(e-b, n_rows)))\n",
    "\n",
    "        if verbose:\n",
    "            print('\\rcalculating textrank sentence similarity {} / {}'.format(b, n_rows), end='')\n",
    "\n",
    "    mat = sp.sparse.vstack(mat)\n",
    "    if verbose:\n",
    "        print('\\rcalculating textrank sentence similarity was done with {} sents'.format(n_rows))\n",
    "\n",
    "    return mat\n",
    "\n",
    "def graph_with_python_sim(tokens, verbose, similarity, min_sim):\n",
    "    if similarity == 'cosine':\n",
    "        similarity = cosine_sent_sim\n",
    "    elif callable(similarity):\n",
    "        similarity = similarity\n",
    "    else:\n",
    "        similarity = textrank_sent_sim\n",
    "\n",
    "    rows, cols, data = [], [], []\n",
    "    n_sents = len(tokens)\n",
    "    for i, tokens_i in enumerate(tokens):\n",
    "        if verbose and i % 1000 == 0:\n",
    "            print('\\rconstructing sentence graph {} / {} ...'.format(i, n_sents), end='')\n",
    "        for j, tokens_j in enumerate(tokens):\n",
    "            if i >= j:\n",
    "                continue\n",
    "            sim = similarity(tokens_i, tokens_j)\n",
    "            if sim < min_sim:\n",
    "                continue\n",
    "            rows.append(i)\n",
    "            cols.append(j)\n",
    "            data.append(sim)\n",
    "    if verbose:\n",
    "        print('\\rconstructing sentence graph was constructed from {} sents'.format(n_sents))\n",
    "    return csr_matrix((data, (rows, cols)), shape=(n_sents, n_sents))\n",
    "\n",
    "def textrank_sent_sim(s1, s2):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    s1, s2 : list of str\n",
    "        Tokenized sentences\n",
    "    Returns\n",
    "    -------\n",
    "    Sentence similarity : float\n",
    "        Non-negative number\n",
    "    \"\"\"\n",
    "    n1 = len(s1)\n",
    "    n2 = len(s2)\n",
    "    if (n1 <= 1) or (n2 <= 1):\n",
    "        return 0\n",
    "    common = len(set(s1).intersection(set(s2)))\n",
    "    base = math.log(n1) + math.log(n2)\n",
    "    return common / base\n",
    "\n",
    "def cosine_sent_sim(s1, s2):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    s1, s2 : list of str\n",
    "        Tokenized sentences\n",
    "    Returns\n",
    "    -------\n",
    "    Sentence similarity : float\n",
    "        Non-negative number\n",
    "    \"\"\"\n",
    "    if (not s1) or (not s2):\n",
    "        return 0\n",
    "\n",
    "    s1 = Counter(s1)\n",
    "    s2 = Counter(s2)\n",
    "    norm1 = math.sqrt(sum(v ** 2 for v in s1.values()))\n",
    "    norm2 = math.sqrt(sum(v ** 2 for v in s2.values()))\n",
    "    prod = 0\n",
    "    for k, v in s1.items():\n",
    "        prod += v * s2.get(k, 0)\n",
    "    return prod / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "green-arcade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def pagerank(x, df=0.85, max_iter=30, bias=None):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    x : scipy.sparse.csr_matrix\n",
    "        shape = (n vertex, n vertex)\n",
    "    df : float\n",
    "        Damping factor, 0 < df < 1\n",
    "    max_iter : int\n",
    "        Maximum number of iteration\n",
    "    bias : numpy.ndarray or None\n",
    "        If None, equal bias\n",
    "    Returns\n",
    "    -------\n",
    "    R : numpy.ndarray\n",
    "        PageRank vector. shape = (n vertex, 1)\n",
    "    \"\"\"\n",
    "\n",
    "    assert 0 < df < 1\n",
    "\n",
    "    # initialize\n",
    "    A = normalize(x, axis=0, norm='l1')\n",
    "    R = np.ones(A.shape[0]).reshape(-1,1)\n",
    "\n",
    "    # check bias\n",
    "    if bias is None:\n",
    "        bias = (1 - df) * np.ones(A.shape[0]).reshape(-1,1)\n",
    "    else:\n",
    "        bias = bias.reshape(-1,1)\n",
    "        bias = A.shape[0] * bias / bias.sum()\n",
    "        assert bias.shape[0] == A.shape[0]\n",
    "        bias = (1 - df) * bias\n",
    "\n",
    "    # iteration\n",
    "    for _ in range(max_iter):\n",
    "        R = df * (A * R) + bias\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "sharp-brazilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class KeysentenceSummarizer:\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    ---------\n",
    "    sents : list of str\n",
    "        Sentence list\n",
    "    tokenize : callable\n",
    "        Tokenize function: tokenize(str) = list of str\n",
    "    min_count : int\n",
    "        Minumum frequency of words will be used to construct sentence graph\n",
    "    min_sim : float\n",
    "        Minimum similarity between sentences in sentence graph\n",
    "    similarity : str\n",
    "        available similarity = ['cosine', 'textrank']\n",
    "    vocab_to_idx : dict or None\n",
    "        Vocabulary to index mapper\n",
    "    df : float\n",
    "        PageRank damping factor\n",
    "    max_iter : int\n",
    "        Number of PageRank iterations\n",
    "    verbose : Boolean\n",
    "        If True, it shows training progress\n",
    "    \"\"\"\n",
    "    def __init__(self, sents=None, tokenize=None, min_count=2,\n",
    "        min_sim=0.3, similarity=None, vocab_to_idx=None,\n",
    "        df=0.85, max_iter=30, verbose=False):\n",
    "\n",
    "        self.tokenize = tokenize\n",
    "        self.min_count = min_count\n",
    "        self.min_sim = min_sim\n",
    "        self.similarity = similarity\n",
    "        self.vocab_to_idx = vocab_to_idx\n",
    "        self.df = df\n",
    "        self.max_iter = max_iter\n",
    "        self.verbose = verbose\n",
    "\n",
    "        if sents is not None:\n",
    "            self.train_textrank(sents)\n",
    "\n",
    "    def train_textrank(self, sents, bias=None):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        sents : list of str\n",
    "            Sentence list\n",
    "        bias : None or numpy.ndarray\n",
    "            PageRank bias term\n",
    "            Shape must be (n_sents,)\n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        g = sent_graph(sents, self.tokenize, self.min_count,\n",
    "            self.min_sim, self.similarity, self.vocab_to_idx, self.verbose)\n",
    "        self.R = pagerank(g, self.df, self.max_iter, bias).reshape(-1)\n",
    "        if self.verbose:\n",
    "            print('trained TextRank. n sentences = {}'.format(self.R.shape[0]))\n",
    "\n",
    "    def summarize(self, sents, topk=30, bias=None):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        sents : list of str\n",
    "            Sentence list\n",
    "        topk : int\n",
    "            Number of key-sentences to be selected.\n",
    "        bias : None or numpy.ndarray\n",
    "            PageRank bias term\n",
    "            Shape must be (n_sents,)\n",
    "        Returns\n",
    "        -------\n",
    "        keysents : list of tuple\n",
    "            Each tuple stands for (sentence index, rank, sentence)\n",
    "        Usage\n",
    "        -----\n",
    "            >>> from textrank import KeysentenceSummarizer\n",
    "            >>> summarizer = KeysentenceSummarizer(tokenize = tokenizer, min_sim = 0.5)\n",
    "            >>> keysents = summarizer.summarize(texts, topk=30)\n",
    "        \"\"\"\n",
    "        n_sents = len(sents)\n",
    "        if isinstance(bias, np.ndarray):\n",
    "            if bias.shape != (n_sents,):\n",
    "                raise ValueError('The shape of bias must be (n_sents,) but {}'.format(bias.shape))\n",
    "        elif bias is not None:\n",
    "            raise ValueError('The type of bias must be None or numpy.ndarray but the type is {}'.format(type(bias)))\n",
    "\n",
    "        self.train_textrank(sents, bias)\n",
    "        idxs = self.R.argsort()[-topk:]\n",
    "        keysents = [(idx, self.R[idx], sents[idx]) for idx in reversed(idxs)]\n",
    "        return keysents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "cooked-smoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 인도에 이어 베트남에서 신종 코로나 바이러스 감염증(코로나19) 변이 바이러스가 확산함에 따라 현지에서 대규모 생산시설을 운영하고 있는 삼성전자와 LG전자에도 비상이 걸렸다. 베트남 지방정부가 코로나19 확산 방지를 위해 이동제한 등의 방역조치를 시행하고 있어 각 시설 생산 차질 우려가 나오는 것이다.3일(현지시각) 베트남 보건당국에 따르면 북부 박장성(北江省)과 박닌성(北寧省) 지역에서는 전날 각각 48명, 3명의 신규 확진자가 발생했다. 지난 4월 27일 이후 전날까지 이 지역 누적 확진자는 박장성 2424명, 박닌성 879명으로, 같은 기간 베트남 전체 확진자(4549명)의 72.6%를 차지하고 있다.이곳에는 삼성전자를 비롯한 전자 계열사들이 대규모 생산시설을 운영 중에 있다. 박닌성 옌퐁에는 약 2만명이 일하고 있는 삼성전자의 스마트폰 공장이 있는데, 이 공장은 삼성전자의 전 세계 스마트폰 출하량의 절반 이상을 담당하고 있는 것으로 알려졌다. 또 삼성디스플레이(직원수 약 3만5000명)와 삼성SDI(2400명)도 해당 지역에서 각각 디스플레이 패널, 배터리 공장을 운영하고 있다.삼성전자는 지난달 박장성 협력업체 직원 40여명이 코로나19에 집단 감염돼 공장 가동이 멈추는 바람에 부품 공급에 애를 먹었다. 이 상황에서 스마트폰 공장의 현지 근로자 2명이 지난달 12일 확진 판정을 받기도 했다. 다만 이들은 유행이 본격화한 4월 말부터 휴가 중으로, 공장 출근을 하지 않아 다른 직원과의 접촉은 없었던 것으로 전해졌다. 공장 가동 중단도 이뤄지지 않았다.여기에 베트남 각 지역 정부들이 1일 오전 0시(현지시각)을 기해 해당 지역에 이동제한 명령을 내리면서 생산 차질이 일부 우려되는 상황이다. 72시간 이내의 코로나19 진단검사에서 음성이 확인될 경우에는 출퇴근이 가능하다고 하지만, 업무에는 상당한 영향이 아닐 수 없다. 현재 삼성전자 스마트폰 공장 직원 2만명 중 절반쯤이 외부 지역에서 출퇴근을 하고 있는 것으로 알려졌다. 삼성전자 관계자는 “현재 공장 내 기숙사에 들어가면 2주간 외부 출입을 하지 못하도록 조치하고 있다”라며 “최대한 (직원들이) 이동하지 않게끔 인근 숙박시설을 마련하는 등 대책을 마련하고 있다”고 했다.공장 내 집단감염이 현실화 할 경우 생산차질로 인한 피해는 막심할 수밖에 없다. 특히 보통 글로벌 기업의 대규모 공장 인근에는 이들의 부품을 조달하는 협력사들도 많아 코로나19 확산은 자칫 공급망 전체의 위기로 번질 가능성이 있다. 국내 중소기업의 베트남 현지 공장 150여곳이 최근 코로나19 확산 여파로 가동을 멈추기도 했다.이 때문에 삼성전자는 현지 직원을 대상으로 한 백신 접종에도 돌입했다. 전자 계열사인 삼성디스플레이와 삼성SDI 등의 직원들도 함께 백신을 맞는다. 해당 백신은 베트남 정부가 기업별로 할당한 영국 아스트라제네카 백신으로, 삼성 계열 3사의 접종 대상자는 1만5000여명이라는 게 회사 측 설명이다. 이들의 협력사에도 백신이 지원될 것으로 알려졌다. 회사 관계자는 “우선 생산라인의 현지인 직원들을 대상으로 백신 접종을 시작했다”라며 “한국인 주재원들의 접종 신청도 받고 있다”고 했다.문제는 최근 베트남에서 영국 변이 바이러스와 인도 변이 바이러스의 특성이 섞인 신종 변이 바이러스가 발견됐다는 점이다. 영국 변이는 전염성이 높아 확산이 빠르고, 인도 변이는 코로나19를 무력화하는 중화항체가 잘 듣지 않는다. 응우옌 탄 롱 베트남 보건부 장관은 “새 변이 바이러스는 공기를 통해 빠르게 전파되며, 배양 실험에서 이전 바이러스보다 더 빠르게 자기 복제가 이뤄지는 모습이 관찰됐다”고 밝혔다.코로나19가 확산하는 지역은 아니지만 역시 베트남에 생산거점을 두고 있는 LG전자도 현지 상황을 면밀하게 관찰하고 있다. LG전자는 베트남 북부 하이퐁시에 지난 2015년 ‘LG 하이퐁 캠퍼스’를 설립하고, 다양한 생활가전 제품을 생산하고 있다. 현지 직원은 약 1만6000명이다. 자동차 부품을 만드는 공장도 있다. 또 LG디스플레이, LG이노텍 등의 계열사 공장이 있다.LG전자 관계자는 “공장의 일부 생산라인의 가동률을 조정하고, 박장성이나 박닌성으로부터 출퇴근하는 근로자의 임시 거처 숙소비를 지원하는 등의 대응을 짜고 있다”라며 “최악의 상황에 대비한 대응 전략을 갖추고 있다”고 했다. LG디스플레이와 LG이노텍 역시 비슷한 대책을 세우고 있다. LG디스플레이와 이노텍 측은 “현지는 아직 코로나19의 급격한 확산이 일어나지는 않고 있으나, 상황을 예의주시하고 있다”고 했다. 코로나19 급속 확산 베트남…삼성·LG, 공급망 무너질까 노심초사.\n",
      "\n",
      "LG전자는 베트남 북부 하이퐁시에 지난 2015년 ‘LG 하이퐁 캠퍼스’를 설립하고, 다양한 생활가전 제품을 생산하고 있다.\n",
      "국내 중소기업의 베트남 현지 공장 150여곳이 최근 코로나19 확산 여파로 가동을 멈추기도 했다.\n",
      "삼성전자 관계자는 “현재 공장 내 기숙사에 들어가면 2주간 외부 출입을 하지 못하도록 조치하고 있다”라며 “최대한 (직원들이) 이동하지 않게끔 인근 숙박시설을 마련하는 등 대책을 마련하고 있다”고 했다.\n",
      "베트남 지방정부가 코로나19 확산 방지를 위해 이동제한 등의 방역조치를 시행하고 있어 각 시설 생산 차질 우려가 나오는 것이다.\n",
      "특히 보통 글로벌 기업의 대규모 공장 인근에는 이들의 부품을 조달하는 협력사들도 많아 코로나19 확산은 자칫 공급망 전체의 위기로 번질 가능성이 있다.\n"
     ]
    }
   ],
   "source": [
    "summarizer = KeysentenceSummarizer(\n",
    "    tokenize = lambda x:x.split(),\n",
    "    min_sim = 0.3,\n",
    "    verbose = False\n",
    ")\n",
    "keysents = summarizer.summarize(text_list, topk=5)\n",
    "print(sents)\n",
    "print()\n",
    "for _, _, text_list in keysents:\n",
    "    print(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-communications",
   "metadata": {},
   "source": [
    "기사마다 고유의 아이디가 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-closer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-canadian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-engagement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-terminal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-ceremony",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-values",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-netherlands",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-commissioner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-contributor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-bradley",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
