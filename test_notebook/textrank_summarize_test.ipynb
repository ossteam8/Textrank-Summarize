{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accessible-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: cp949 -*- \n",
    "import platform\n",
    "import kss\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "if platform.system() == \"Windows\":\n",
    "    try:\n",
    "        from eunjeon import Mecab\n",
    "    except:\n",
    "        print(\"please install eunjeon module\")\n",
    "else:  # Ubuntu일 경우\n",
    "    from konlpy.tag import Mecab\n",
    "\n",
    "from typing import List, Callable, Union, Any, TypeVar, Tuple, Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "liberal-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(tokenizer_name):\n",
    "    tokenizer = Mecab()\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fourth-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(sent: List[str], noun=False, tokenizer=\"mecab\") -> List[str]:\n",
    "    tokenizer = get_tokenizer(tokenizer)\n",
    "    \n",
    "    if noun:\n",
    "        nouns = tokenizer.nouns(sent)\n",
    "        nouns = [word for word in nouns if len(word) > 1]\n",
    "        return nouns\n",
    "\n",
    "    return tokenizer.morphs(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pregnant-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vectorize_sents(\n",
    "    sents: List[str],\n",
    "    stopwords=None,\n",
    "    min_count=2,\n",
    "    tokenizer=\"mecab\",\n",
    "    noun=False\n",
    "):\n",
    "\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        stop_words=stopwords,\n",
    "        tokenizer=partial(get_tokens, noun=noun, tokenizer=\"mecab\"),\n",
    "        min_df=min_count,\n",
    "    )\n",
    "\n",
    "    vec = vectorizer.fit_transform(sents)\n",
    "    print(vec.toarray())\n",
    "    vocab_idx = vectorizer.vocabulary_\n",
    "    idx_vocab = {idx: vocab for vocab, idx in vocab_idx.items()}\n",
    "    return vec, vocab_idx, idx_vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "liable-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(x, min_sim=0.3, min_length=1):\n",
    "\n",
    "    # binary csr_matrix\n",
    "    numerators = (x > 0) * 1\n",
    "\n",
    "    #문장간 유사도 계산, 문장간 유사도가 0.3이하면 간선 연결하지 않음.\n",
    "    min_length = 1\n",
    "    denominators = np.asarray(x.sum(axis=1))\n",
    "    denominators[np.where(denominators <= min_length)] = 10000\n",
    "    denominators = np.log(denominators)\n",
    "    denom_log1 = np.matmul(denominators, np.ones(denominators.shape).T)\n",
    "    denom_log2 = np.matmul(np.ones(denominators.shape), denominators.T)\n",
    "\n",
    "    sim_mat = np.dot(numerators, numerators.T)\n",
    "    sim_mat = sim_mat / (denom_log1 + denom_log2)\n",
    "    sim_mat[np.where(sim_mat <= min_sim)] = 0\n",
    "\n",
    "    return sim_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-advice",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "active-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sent_graph(\n",
    "    sents: List[str],\n",
    "    min_count=2,\n",
    "    min_sim=0.3,\n",
    "    tokenizer=\"mecab\",\n",
    "    noun=False,\n",
    "    stopwords: List[str] = [\"연합뉴스\", \"중앙일보\",\"한겨레\",\"국민일보\",\"머니투데이\",\"동아일보\"]\n",
    "):\n",
    "    \n",
    "    # TF-IDF + Cosine similarity \n",
    "\n",
    "    mat, vocab_idx, idx_vocab = vectorize_sents(\n",
    "        sents, stopwords, min_count=min_count, tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    \n",
    "    mat = similarity_matrix(mat, min_sim=min_sim)\n",
    "\n",
    "    return mat, vocab_idx, idx_vocab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "small-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(mat: np.ndarray, df=0.85, max_iter=50):\n",
    "    \n",
    "    assert 0 < df < 1\n",
    "\n",
    "    A = normalize(mat, axis=0, norm=\"l1\")\n",
    "    N = np.ones(A.shape[0]) / A.shape[0]\n",
    "\n",
    "    R = np.ones(A.shape[0])\n",
    "    # iteration\n",
    "    for _ in range(max_iter):\n",
    "        R = df * np.matmul(A, R) + (1 - df) * N\n",
    "\n",
    "\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "prospective-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.11449275 0.16624464 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.16624464 0.         0.         0.\n",
      "  0.         0.12302476 0.         0.2707945  0.         0.\n",
      "  0.         0.         0.16624464 0.         0.         0.2707945\n",
      "  0.         0.         0.21634389 0.         0.2707945  0.\n",
      "  0.         0.2707945  0.36095639 0.         0.2707945  0.\n",
      "  0.2707945  0.         0.         0.         0.         0.1804782\n",
      "  0.15368975 0.1322996  0.         0.         0.         0.\n",
      "  0.         0.21634389 0.         0.         0.         0.\n",
      "  0.21634389 0.24012951 0.         0.         0.21634389 0.        ]\n",
      " [0.         0.08451745 0.12272021 0.         0.19989792 0.17726131\n",
      "  0.19989792 0.         0.         0.19989792 0.         0.159703\n",
      "  0.26645457 0.35452263 0.         0.17726131 0.         0.\n",
      "  0.11345231 0.09081571 0.19989792 0.         0.17726131 0.\n",
      "  0.         0.         0.12272021 0.17726131 0.         0.19989792\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13322728 0.34035694 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.26645457\n",
      "  0.11345231 0.0976623  0.         0.159703   0.         0.\n",
      "  0.         0.         0.         0.         0.         0.29071363\n",
      "  0.159703   0.17726131 0.         0.         0.         0.        ]\n",
      " [0.         0.19064852 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3998536  0.         0.         0.         0.3998536\n",
      "  0.25591774 0.20485568 0.45091565 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.45091565 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.36024679 0.        ]\n",
      " [0.41956655 0.08869701 0.12878897 0.         0.20978327 0.\n",
      "  0.         0.         0.         0.20978327 0.         0.16760064\n",
      "  0.13981564 0.18602725 0.25757795 0.         0.         0.18602725\n",
      "  0.         0.09530673 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.18602725 0.18602725 0.\n",
      "  0.         0.         0.16760064 0.18602725 0.         0.18602725\n",
      "  0.20978327 0.         0.13981564 0.23812552 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.13981564\n",
      "  0.11906276 0.1024919  0.         0.16760064 0.         0.\n",
      "  0.20978327 0.16760064 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.20978327 0.         0.20978327]\n",
      " [0.         0.07392499 0.21467969 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.17484497 0.13968763\n",
      "  0.         0.         0.10733985 0.         0.17484497 0.\n",
      "  0.09923348 0.07943389 0.         0.         0.15504539 0.\n",
      "  0.         0.46513616 0.         0.         0.         0.\n",
      "  0.15504539 0.17484497 0.         0.         0.         0.\n",
      "  0.         0.         0.23306017 0.29770045 0.         0.\n",
      "  0.         0.17484497 0.31009077 0.15504539 0.         0.23306017\n",
      "  0.         0.08542241 0.31009077 0.         0.         0.\n",
      "  0.         0.13968763 0.         0.15504539 0.         0.\n",
      "  0.13968763 0.         0.17484497 0.         0.         0.        ]\n",
      " [0.         0.10321062 0.14986288 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14986288 0.         0.         0.\n",
      "  0.27709031 0.11090189 0.         0.         0.         0.19502535\n",
      "  0.21646713 0.21646713 0.14986288 0.         0.         0.\n",
      "  0.21646713 0.24411039 0.         0.         0.         0.\n",
      "  0.         0.         0.16269386 0.27709031 0.         0.\n",
      "  0.         0.24411039 0.21646713 0.21646713 0.         0.16269386\n",
      "  0.13854515 0.23852557 0.         0.         0.24411039 0.\n",
      "  0.         0.         0.         0.21646713 0.24411039 0.17750614\n",
      "  0.19502535 0.         0.         0.         0.         0.        ]\n",
      " [0.         0.07598026 0.11032412 0.         0.         0.\n",
      "  0.         0.31871194 0.31871194 0.         0.17970603 0.\n",
      "  0.35930959 0.         0.         0.15935597 0.17970603 0.\n",
      "  0.10199238 0.24492697 0.         0.         0.         0.14357124\n",
      "  0.15935597 0.         0.22064823 0.15935597 0.         0.\n",
      "  0.15935597 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.20398476 0.         0.\n",
      "  0.         0.         0.15935597 0.         0.31871194 0.\n",
      "  0.         0.08779733 0.         0.28714248 0.17970603 0.\n",
      "  0.         0.         0.17970603 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.14357124 0.        ]\n",
      " [0.         0.13921562 0.         0.         0.         0.\n",
      "  0.         0.29198163 0.29198163 0.         0.         0.\n",
      "  0.21944957 0.         0.20214251 0.         0.         0.\n",
      "  0.1868766  0.29917999 0.         0.         0.         0.\n",
      "  0.         0.         0.20214251 0.         0.29198163 0.\n",
      "  0.         0.         0.         0.         0.         0.29198163\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.29198163 0.\n",
      "  0.         0.16086758 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.23942911\n",
      "  0.         0.         0.32926823 0.32926823 0.         0.        ]\n",
      " [0.         0.09338443 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14720455 0.         0.         0.         0.         0.\n",
      "  0.12535492 0.         0.         0.22086979 0.         0.17645791\n",
      "  0.19585831 0.         0.40678543 0.         0.         0.\n",
      "  0.         0.         0.         0.19585831 0.         0.\n",
      "  0.         0.22086979 0.         0.12535492 0.         0.44173958\n",
      "  0.         0.         0.         0.         0.19585831 0.\n",
      "  0.25070985 0.10790834 0.19585831 0.         0.         0.\n",
      "  0.44173958 0.         0.         0.         0.         0.16060662\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.09689566 0.         0.         0.         0.\n",
      "  0.         0.20322254 0.20322254 0.         0.         0.18309268\n",
      "  0.30547881 0.         0.         0.20322254 0.         0.\n",
      "  0.13006824 0.20823268 0.         0.         0.20322254 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18309268 0.20322254 0.         0.\n",
      "  0.45834888 0.         0.         0.26013648 0.22917444 0.22917444\n",
      "  0.         0.         0.         0.         0.         0.30547881\n",
      "  0.         0.11196567 0.20322254 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.18309268 0.        ]\n",
      " [0.         0.19158038 0.         0.45311964 0.         0.401808\n",
      "  0.45311964 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.20585698 0.         0.         0.         0.\n",
      "  0.         0.         0.27817667 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.25716862 0.         0.         0.         0.         0.45311964\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.         0.12905645 0.18739129 0.30524009 0.         0.27067445\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18739129 0.         0.         0.\n",
      "  0.         0.13867376 0.         0.         0.         0.24386326\n",
      "  0.         0.27067445 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.20343538 0.         0.         0.\n",
      "  0.         0.         0.         0.27067445 0.         0.\n",
      "  0.17323939 0.14912837 0.         0.24386326 0.         0.30524009\n",
      "  0.         0.24386326 0.         0.27067445 0.30524009 0.22195692\n",
      "  0.         0.         0.         0.         0.         0.        ]\n",
      " [0.73182128 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.14975854 0.         0.         0.21631641\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.21631641 0.\n",
      "  0.         0.         0.19488957 0.         0.24394043 0.21631641\n",
      "  0.         0.         0.         0.13844869 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.13844869 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.24394043 0.         0.         0.\n",
      "  0.         0.21631641 0.         0.         0.         0.24394043]]\n",
      "['여기에 사건에 대한 진실 규명을 요구하는 단체가 경찰과 A씨의 휴대전화를 발견한 환경미화원을 검찰에 고발하면서 이른바 ‘한강 대학생 사건’이 고소·고발전으로 번지고 있다.', 'A씨 측 반격 \"수만명 고소해야\" 손씨의 사망 원인을 밝히기 위한 경찰 수사가 마무리 단계에 접어들었지만 고소·고발에 집회까지 이어지면서 혼란이 가중되고 있다.', 'A씨를 대리하는 정 변호사의 고소 대상에는 유튜버와 블로거뿐 아니라 인터넷 커뮤니티 등에 게시글이나 댓글을 작성한 이들도 포함될 예정이다.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['국민', '머니', '일보', '투데이'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    }
   ],
   "source": [
    "news3 = \"\"\"한강에서 사망한 채 발견된 손정민씨의 실종 당일 함께 술을 마셨던 A씨 측이 대규모 고소를 예고했다. 여기에 사건에 대한 진실 규명을 요구하는 단체가 경찰과 A씨의 휴대전화를 발견한 환경미화원을 검찰에 고발하면서 이른바 ‘한강 대학생 사건’이 고소·고발전으로 번지고 있다. 해당 단체는 추가 고발까지 예고했다.A씨 측 반격 \"수만명 고소해야\" 손씨의 사망 원인을 밝히기 위한 경찰 수사가 마무리 단계에 접어들었지만 고소·고발에 집회까지 이어지면서 혼란이 가중되고 있다. 5일 A씨 측 등에 따르면 정병원 변호사(법무법인 원앤파트너스)는 A씨와 그 가족 등에 대한 허위사실을 제기한 유튜버와 블로거 등을 7일부터 경찰에 고소할 예정이다.A씨를 대리하는 정 변호사의 고소 대상에는 유튜버와 블로거뿐 아니라 인터넷 커뮤니티 등에 게시글이나 댓글을 작성한 이들도 포함될 예정이다. 정 변호사는 “수차례 친구 A 및 그 가족과 주변인들에 관한 위법행위를 멈춰달라고 요청했음에도 게시물이 오히려 늘어나고 있다”며 “일부 내용은 수인한도를 넘어서면서 피해와 고통은 점점 더 심해지고 있다”고 밝혔다. 이어 “선처를 희망하는 사람이 전혀 없다면 최소 수만 명은 고소해야 할 것 같다”고 덧붙였다.이들은 지난달 29일에도 집회를 열고 손씨의 실종 당일 목격자의 제보를 독려하는 집회를 열어다. 지난 1일에는 서울 종로구 서울경찰청 앞에서 기자회견을 열고 “수사당국이 경찰 초동수사 부실 논란과 손씨 사망 경위에 대한 의혹을 피해왔다”고 주장했다. 반진사를 만든 건 유튜브 ‘종이의 TV’ 채널 운영자다. A씨 측이 명예훼손 등 혐의로 고소하겠다고 밝힌 유튜버 중엔 '종이의 TV‘도 포함돼 있다.손정민 친구 \"수만명 고소\"에 \"끝까지 간다\"…혼란의 한강 사망\"\"\"\n",
    "#즉, 입력값 str 형태\n",
    "\n",
    "sents= kss.split_sentences(news3)\n",
    "mat, vocab_idx, idx_vocab = sent_graph(sents)\n",
    "R = pagerank(mat)\n",
    "topk = 3\n",
    "idxs = R.argsort()[-topk:]\n",
    "#keysents = [(idx, R[idx], sents[idx]) for idx in sorted(idxs)]\n",
    "#for idx in sorted(idxs):\n",
    "    #print(sents[idx])\n",
    "keysents = [(sents[idx]) for idx in sorted(idxs)]\n",
    "print(keysents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-cameroon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-soccer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-integration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "hindu-celebrity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "proud-cisco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "affiliated-morocco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-consent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "instrumental-suggestion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "reserved-reading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "married-poultry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "major-trigger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-gardening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "swedish-cylinder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "prostate-forest",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-kingston",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-influence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-ribbon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-country",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-appearance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-refund",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
